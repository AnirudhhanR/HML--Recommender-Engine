# -*- coding: utf-8 -*-
"""Genre Based Content Recommendation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hy2DJuAFmlwND0KvtB04KLXjXKkH0gxt
"""

!pip install gdown pyunpack

! gdown 'https://drive.google.com/uc?id=1ZpdsOnCnoyBKQOVIxB5h9GAve3D05P7P'  #anime
! gdown 'https://drive.google.com/uc?id=1lmPQpgGHxXQz3WiEZ9Hla6EL58n34hrt'  #rating

#!pip install kaggle
#from google.colab import drive
#drive.mount('/content/drive')
#! mkdir ~/.kaggle
#!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json
#! chmod 600 ~/.kaggle/kaggle.json
#! kaggle datasets download CooperUnion/anime-recommendations-database

#! unzip /content/anime-recommendations-database.zip

import random
import csv
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import itertools
import collections
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import jaccard_score # Jaccard Similarity

"""## Preprocessing ##

In preprocessing I split the genre (turn them into a list), so later I can turn them to feature (binary encoding of genres).

Oh the plot meant to show number of anime per genre (just curious... not really needed)
"""

animes = pd.read_csv('/content/anime.csv') # load the data
animes['genre'] = animes['genre'].fillna('None') # filling 'empty' data
animes['genre'] = animes['genre'].apply(lambda x: x.split(', ')) # split genre into list of individual genre

genre_data = itertools.chain(*animes['genre'].values.tolist()) # flatten the list
genre_counter = collections.Counter(genre_data)
genres = pd.DataFrame.from_dict(genre_counter, orient='index').reset_index().rename(columns={'index':'genre', 0:'count'})
genres.sort_values('count', ascending=False, inplace=True)

# Plot genre
f, ax = plt.subplots(figsize=(8, 12))
sns.set_color_codes("pastel")
sns.set_style("white")
sns.barplot(x="count", y="genre", data=genres, color='b')
ax.set(ylabel='Genre',xlabel="Anime Count")

"""## Feature Extraction ##

The feature extraction is simple, a binary encoded vector of genre.
"""

genre_map = {genre: idx for idx, genre in enumerate(genre_counter.keys())}
def extract_feature(genre):
    feature = np.zeros(len(genre_map.keys()), dtype=int)
    feature[[genre_map[idx] for idx in genre]] += 1
    return feature

anime_feature = pd.concat([animes['name'], animes['genre']], axis=1)
anime_feature['genre'] = anime_feature['genre'].apply(lambda x: extract_feature(x))
print(anime_feature.head(80))

animeID = []
for i in range(5):
    animeID.append(random.randint(1, 12294))
print(animeID)

saving = []
save1 = []

test_data = anime_feature.take(animeID)
for row in test_data.iterrows():
    print('Similar anime like {}:'.format(row[1]['name']))
    search = anime_feature.drop([row[0]]) # drop current anime
    search['result'] = search['genre'].apply(lambda x: jaccard_score(row[1]['genre'], x))
    print(search.nlargest(5,['result'])['result'])

    search_result = search.sort_values('result', ascending=False)['name'].head(5)
    for res in search_result.values:
        print('\t{}'.format(res))
    print()